\section{Dimensionality Reduction}

\subsection{Pricipal Component Analysis (PCA)}
Prinicipal component analysis creates a lower-dimensional subspace of uncorrelated variables (called prinicipal components) s.t.\ the projections of the datapoints have maximal variance.

\newpar{}
\ptitle{Properties}
\begin{itemize}
    \item global (same transformation in entire data space), linear
    \item preserves variance
    \item reduces noise (low pass filter)
    \item components have the same dimension as the data points
    \item the transformed/projected data points have the dimension of the number of components
\end{itemize}

\newpar{}
\ptitle{\code{PCA(Dataset $D$, $n_{components}$)}}
\fncode{
    \begin{algorithmic}
        \setstretch{1.5}
        \ForAll{$j = 1,\ldots n_{components}$ }
        \State{Find projection direction $\mathbf{u}_j$ that maximizes\newline variance of projection of $D$ and is orthogonal to $\mathcal{U}$}
        \State{Calculate covariance $S = \frac{1}{N}\sum\limits_{i=1}^{N} (\mathbf{x}_i-\bar{\mathbf{x}}){(\mathbf{x}_i-\bar{\mathbf{x}})}^{\mathsf{T}}$}
        \State{Eigenvalue $\lambda_j \gets \arg\max\limits_{\lambda}\underbrace{\mathbf{u}_j^{\mathsf{T}}\mathbf{S}\mathbf{u}_j}_{\textsf{var. proj.}} + \lambda(1-\mathbf{u}_j^{\mathsf{T}}\mathbf{u}_j)$}
        \State{$\Lambda,\mathcal{U}\gets \lambda_j, \mathbf{u}_j$}
        \EndFor{}
        \State{\Return{$\Lambda,\mathcal{U}$}}
    \end{algorithmic}
}

\subsection{t-distributed Stochastic Neighbour Embedding (t-SNE)}
\begin{itemize}
    \item non-linear and stochastic
    \item preserves distances between datapoints in neighbourhood, in original and projected space.
\end{itemize}